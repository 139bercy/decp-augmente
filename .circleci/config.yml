---
version: 2
jobs:
  install_requirements:
    docker:
      - image: 139bercy/decp-rama
    resource_class: large
    steps:
      - checkout
      - restore_cache:
          keys:
            - dependencies-{{ .Branch }}-{{ checksum "requirements.txt"}}-{{ checksum "confs/config_data.json"}}-{{ checksum "confs/config-circleci.json"}}
            - dependencies-master-{{ checksum "requirements.txt"}}
      - run:
          name: Installation des requirements
          command: |
            python3 -m venv venv
            . venv/bin/activate
            pip install -r requirements.txt
      - save_cache:
          key: dependencies-{{ .Branch }}-{{ checksum "requirements.txt"}}-{{ checksum "confs/config_data.json"}}-{{ checksum "confs/config-circleci.json"}}
          paths:
            - "venv"
            - "confs/config_data.json"

  linter:
    docker:
      - image: 139bercy/decp-rama
    resource_class: large
    steps:
      - checkout
      - restore_cache:
          keys:
            - dependencies-{{ .Branch }}-{{ checksum "requirements.txt"}}-{{ checksum "confs/config-circleci.json"}}
      - run:
          name: Linter
          command: |
            . venv/bin/activate
            pip install pylint
            PYTHON_FILE="$(ls *.py)"
            pylint $PYTHON_FILE
  get_data_daily:
      docker:
        - image: 139bercy/decp-rama
      resource_class: large
      steps:
        - checkout
        - run: date +%F > date
        - run:
            name: Condition pour les branches
            command: |
              if [ "$CIRCLE_BRANCH" != "master" ]; then
                  if [ $(git diff --name-only master..${CIRCLE_BRANCH} | grep "get-data-daily.sh" | wc -l) = 0 ]; then
                    commit_id_head=$(git log -n1 --format=format:"%H")
                    commit_id_head1=$(git log -n2 --format=format:"%H" | tail -1)
                    if [ $(git diff --name-only ${commit_id_head1} ${commit_id_head} | grep "get-data-daily.sh" | wc -l) = 0 ]; then
                      circleci-agent step halt
                    fi
                  fi
              fi
        - run:
            name: Récupération des données utiles
            no_output_timeout: 1h
            command: |
              bash get-data-daily.sh
        - save_cache:
           key: data-input-daily-{{ checksum "date" }}-{{ checksum "get-data-daily.sh" }}
           paths:
             - "data"

  get_data_weekly:
     docker:
       - image: 139bercy/decp-rama
     resource_class: large
     steps:
       - checkout
       - run: date +%G-%V > date
       - run:
           name: Condition pour les branches
           command: |
             if [ "$CIRCLE_BRANCH" != "master" ]; then
                 if [ $(git diff --name-only master..${CIRCLE_BRANCH} | grep "get-data-weekly.sh" | wc -l) = 0 ]; then
                   commit_id_head=$(git log -n1 --format=format:"%H")
                   commit_id_head1=$(git log -n2 --format=format:"%H" | tail -1)
                   if [ $(git diff --name-only ${commit_id_head1} ${commit_id_head} | grep "get-data-weekly.sh" | wc -l) = 0 ]; then
                     circleci-agent step halt
                   fi
                 fi
             fi
       - run:
           name: Récupération des données utiles
           no_output_timeout: 1h
           command: |
             bash get-data-weekly.sh
       - save_cache:
          key: data-input-weekly-v2-{{ checksum "date" }}-{{ checksum "get-data-weekly.sh" }}
          paths:
            - "data"

  gestion_flux:
        docker:
            - image: 139bercy/decp-rama
        resource_class: large
        steps:
          - checkout
          - run: date +%F > date-today
          - run: date --date='1 day ago' +%F > date-yesterday
          - run: date +%F > date
          - run: date +%G-%V > date-weekly
          - restore_cache:
              keys:
                - hashkeys3-{{ .Branch }}-{{ checksum "date-yesterday"}}
          - restore_cache:
              keys: 
                - data-input-daily-{{ checksum "date" }}-{{ checksum "get-data-daily.sh" }}
          - restore_cache:
              keys:
                - dependencies-{{ .Branch }}-{{ checksum "requirements.txt"}}
          - run:
              name: Gestion des flux
              no_output_timeout: 30m
              command: |
                  . venv/bin/activate
                  python3 gestion_flux.py
          - save_cache:
              key: hashkeys3-{{ .Branch }}-{{ checksum "date-today"}}
              paths:
                - "data/hash_keys_modifications.pkl"
                - "data/hash_keys_no_modifications.pkl"
          - persist_to_workspace:
              root: ~/project
              paths:
                - "df_flux.pkl"
                - "columns_modifications.pkl"
                
  nettoyage_flux:
        docker:
            - image: 139bercy/decp-rama
        resource_class: large
        steps:
          - checkout
          - attach_workspace:
              at: ~/project
          - run: date +%G-%V > date
          - restore_cache:
              keys: 
                - data-input-weekly-v2-{{ checksum "date" }}-{{ checksum "get-data-weekly.sh" }}
          - restore_cache:
              keys:
                - dependencies-{{ .Branch }}-{{ checksum "requirements.txt"}}
          - run:
              name: Nettoyage flux
              no_output_timeout: 35m
              command: |
                  . venv/bin/activate
                  python3 nettoyage.py
          - persist_to_workspace:
              root: ~/project
              paths:
                - "df_flux.pkl"
                - "columns_modifications.pkl"
                - "df_nettoye.pkl"
  enrichissement_flux:
        docker:
            - image: 139bercy/decp-rama
        resource_class: large
        steps:
          - checkout
          - run: date +%G-%V > date
          - run: date +%F > date-today
          - run: date --date='1 day ago' +%F > date-yesterday
          - attach_workspace:
              at: ~/project
          - restore_cache:
              keys:
                - cache_acheteur_uniteLegale2-{{ .Branch }}-{{ checksum "date-yesterday"}}
          - restore_cache:
              keys:
                - cache_uniteLegale2-{{ .Branch }}-{{ checksum "date-yesterday"}}
          - restore_cache:
              keys:
                - cache_stockEtablissement2-{{ .Branch }}-{{ checksum "date-yesterday"}}
          - restore_cache:
              keys: 
                - data-input-weekly-v2-{{ checksum "date" }}-{{ checksum "get-data-weekly.sh" }}
          - restore_cache:
              keys:
                - dependencies-{{ .Branch }}-{{ checksum "requirements.txt"}}
          - restore_cache:
              keys:
                - cache_df2-{{ .Branch }}-{{ checksum "date-yesterday"}}
          - run:
              name: Enrichissement flux
              no_output_timeout: 35m
              command: |
                  . venv/bin/activate
                  python3 enrichissement.py
          - save_cache:
              key: cache_acheteur_uniteLegale2-{{ .Branch }}-{{ checksum "date-today"}}
              paths:
                - "cache/cache_acheteur_NOTIN_StockUniteLegale_utf8.pkl"
                - "cache/cache_acheteur_StockUniteLegale_utf8.pkl"
          - save_cache:
              key: cache_uniteLegale2-{{ .Branch }}-{{ checksum "date-today"}}
              paths:
                - "cache/cache_StockUniteLegale_utf8.pkl"
                - "cache/cache_NOTIN_StockUniteLegale_utf8.pkl"
          - save_cache:
              key: cache_stockEtablissement2-{{ .Branch }}-{{ checksum "date-today"}}
              paths:
                - "cache/cache_StockEtablissement_utf8.pkl"
                - "cache/cache_NOTIN_StockEtablissement_utf8.pkl"
          - save_cache:
              key: cache_df2-{{ .Branch }}-{{ checksum "date-today"}}
              paths:
                - "data/cache_df.pkl"
          - persist_to_workspace:
              root: ~/project
              paths:
                - "decp_augmente_flux.csv"


  send:
    docker:
      - image: 139bercy/decp-rama
    resource_class: large
    steps:
      - checkout
      - attach_workspace:
          at: ~/project
      - run: date +%F > date
      - restore_cache:
          keys:
            - data-out-{{ .Branch }}-{{ checksum "date" }}
      - run:
          name: Transfert des données vers data.economie
          command: |
            lftp -u ${DEPLOY_USER}:${DEPLOY_PASSWORD} ${DEPLOY_HOST} -e "set ftp:ssl-force true ; set ssl:verify-certificate false; cd decp ; put decp_augmente_flux.csv ; quit"

workflows:
  version: 2
  main:
    jobs:
      - install_requirements
      - get_data_daily:
          requires:
            - install_requirements
      - gestion_flux:
          requires:
            - get_data_daily
      - nettoyage_flux:
          requires:
            - gestion_flux
      - enrichissement_flux:
          requires:
            - nettoyage_flux
      - send:
          requires:
            - enrichissement_flux
    daily-jobs:
      - install_requirements
      - get_data_daily:
          requires:
            - install_requirements
      - gestion_flux:
          requires:
            - get_data_daily
      - nettoyage_flux:
          requires:
            - gestion_flux
      - enrichissement_flux:
          requires:
            - nettoyage_flux
      - send:
          requires:
            - enrichissement_flux 
    triggers:
      - schedule:
          cron: 0 6 * * 2-6
          filters:
            branches:
              only:
                - flux_ci

  daily-data:
    jobs:
      - get_data_daily
    triggers:
      - schedule:
          cron: 0 3 * * *
          filters:
            branches:
              only:
                - flux_ci
  weekly-data:
    jobs:
      - get_data_weekly
    triggers:
      - schedule:
          cron: 0 4 * * 1
          filters:
            branches:
              only:
                - flux_ci

  daily-compute:
    jobs:
      - get_data_daily
      - get_data_weekly
      - install_requirements
      - gestion_flux:
          requires:
            - install_requirements
    triggers:
      - schedule:
          cron: 0 7 * * 2-6
          filters:
            branches:
              only:
                - master